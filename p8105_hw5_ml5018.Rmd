---
title: "p8105_hw5_ml5018"
author: "Luan Mengxiao"
date: 2023-11-02
output: github_document
---

```{r setup, message = FALSE}
library(tidyverse)

options(tibble.print_min = 5)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

## summary of data

Describe the raw data.

```{r}
homicides_data = 
  read_csv("data/homicide-data.csv") |>
  janitor::clean_names()
```

This data set contains data on homicides in 50 large U.S. cities, gathered by the Washington Post. The Post has mapped more than 52,000 homicides in major American cities over the past decade and found that across the country, there are areas where murder is common but arrests are rare.

The data set consists of `r nrow(homicides_data)` observations of `r ncol(homicides_data)` variables. A more detailed summary of the raw data is posted below.

```{r}
skimr::skim(homicides_data)
```

## data manipulation

Create a `city_state` variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

```{r}
homicides_data = 
  homicides_data |>
  mutate(city_state = str_c(city, ", ", state))

homicides_number = 
  homicides_data |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = 
      sum(disposition %in% c("Closed without arrest","Open/No arrest")))
homicides_number
```

## proportion test

For the city of Baltimore, MD, use the `prop.test` function to estimate the proportion of homicides that are unsolved; save the output of `prop.test` as an R object, apply the `broom::tidy` to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r}
Baltimore_number = 
  homicides_number |>
  filter(city_state == "Baltimore, MD")

Baltimore_result = 
  prop.test(x = pull(Baltimore_number, var = 3), 
          n = pull(Baltimore_number, var = 2)) |>
  broom::tidy()
Baltimore_result

list(
  estimate = pull(Baltimore_result, estimate),
  CI_lower = pull(Baltimore_result, conf.low),
  CI_upper = pull(Baltimore_result, conf.high)
  ) |>
  bind_rows() |>
  knitr::kable()

save(Baltimore_result, file = "result/baltimore_result.RData")
```

Now run `prop.test` for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of `purrr::map`, `purrr::map2`, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

```{r}
unsolved_prop = function(city_state_name) {
  city_number = 
    homicides_number |>
    filter(city_state == city_state_name)
  
  city_result = 
    prop.test(x = pull(city_number, var = 3), n = pull(city_number, var = 2)) |>
    broom::tidy() |>
    select(estimate, conf.low, conf.high)
  
  city_result
}

city_name = unique(pull(homicides_data, city_state))
result = 
  expand_grid(city_name) |>
  mutate(test_result = map(city_name, unsolved_prop)) |>
  unnest(test_result)
result
```

Create a plot that shows the estimates and CIs for each city – check out `geom_errorbar` for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r}
result |>
  mutate(city_name = reorder(city_name, estimate)) |>
  ggplot(aes(x = city_name, y = estimate)) +
  geom_point(aes(y = estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 45, size = 5)) +
  labs(x = "city_state", 
       y = "estimate and 95% CI", 
       title = "Proportion Test Results for Unsolved Homisides")
```